{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "format the blocks parquet into csv file.\n",
    "run following command first after installing cryo:\n",
    "\n",
    "cryo blocks -b 18251965:18473543 --rpc <YOUR_ALCHEMY_RPC_URL> -o ./data/blocks --requests-per-second 50\n",
    "\"\"\"\n",
    "import polars as pl\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"./data/blocks/ethereum__blocks__*.parquet\"\n",
    "data_path = os.path.expanduser(data_path)\n",
    "\n",
    "\n",
    "def scan_df():\n",
    "    return pl.scan_parquet(data_path)\n",
    "\n",
    "\n",
    "timestamps_blocks_fees = (\n",
    "    scan_df()\n",
    "    .select(pl.col(\"timestamp\", \"block_number\", \"base_fee_per_gas\"))\n",
    "    .collect(streaming=True)\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    timestamps_blocks_fees, columns=[\"timestamp\", \"blockNumber\", \"baseFeePerGas\"]\n",
    ")\n",
    "df.to_csv(\"./data/blocks/timestamp_blockNumber_baseFeePerGas.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "extract timestamp and opens from csv file downloaded at https://www.binance.com/en/landing/data\n",
    "\n",
    "put original data into raw/ and add the path to .gitignore to avoid the upload error.\n",
    "\"\"\"\n",
    "eth_usdc_1s_df = pl.read_csv(\n",
    "    \"./data/cex_price/raw/ETHUSDT-1s-2023-10.csv\", has_header=False\n",
    ").select([\"column_1\", \"column_2\"])\n",
    "eth_usdc_1s_df.columns = [\"timestamp\", \"price\"]\n",
    "eth_usdc_1s_df = eth_usdc_1s_df.with_columns(pl.col(\"timestamp\") // 1000)\n",
    "eth_usdc_1s_df.write_csv(\"./data/cex_price/ETHUSDT-1s-2023-10-opens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query for events on UNI_V2 WETH_USDT is done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "filter onchain events and save into csv files\n",
    "\"\"\"\n",
    "from dotenv import load_dotenv\n",
    "import web3\n",
    "from datetime import datetime, timezone\n",
    "from utils import *\n",
    "from decimal import Decimal\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "############################################################\n",
    "\n",
    "DEX = \"UNI_V2\"\n",
    "PAIR = \"WETH_USDT\"\n",
    "\n",
    "w3 = web3.Web3(web3.Web3.HTTPProvider(os.getenv(\"ALCHEMY_URL\")))\n",
    "uni_v2_contract = w3.eth.contract(\n",
    "    address=os.getenv(f\"{DEX}_{PAIR}_ADDRESS\"), abi=os.getenv(\"UNI_V2_ABI\")\n",
    ")\n",
    "\n",
    "############################################################\n",
    "\n",
    "# date range\n",
    "(from_block_number, from_block_timestamp) = get_block_from_timestamp(\n",
    "    w3, int(datetime(2023, 10, 1, tzinfo=timezone.utc).timestamp())\n",
    ")\n",
    "(to_block_number, to_block_timestamp) = get_block_from_timestamp(\n",
    "    w3, int(datetime(2023, 11, 1, tzinfo=timezone.utc).timestamp())\n",
    ")\n",
    "\n",
    "############################################################\n",
    "\n",
    "# fetch events and block number; if error occurs reduce the chunk size.\n",
    "chunk_size = 1800  # blocks = 6 hours / 12 seconds ; should be less than 2000 due to alchemy's policy.\n",
    "swaps = []\n",
    "mints = []\n",
    "burns = []\n",
    "syncs = []\n",
    "for block_number in range(from_block_number, to_block_number, chunk_size):\n",
    "    time.sleep(1)\n",
    "\n",
    "    # swaps\n",
    "    swap_logs = uni_v2_contract.events.Swap().get_logs(\n",
    "        fromBlock=block_number, toBlock=block_number + chunk_size - 1\n",
    "    )\n",
    "    swaps.extend(\n",
    "        [\n",
    "            {\n",
    "                \"blockNumber\": swap_log[\"blockNumber\"],\n",
    "                \"amount0In\": Decimal(swap_log[\"args\"][\"amount0In\"]),\n",
    "                \"amount1In\": Decimal(swap_log[\"args\"][\"amount1In\"]),\n",
    "                \"amount0Out\": Decimal(swap_log[\"args\"][\"amount0Out\"]),\n",
    "                \"amount1Out\": Decimal(swap_log[\"args\"][\"amount1Out\"]),\n",
    "            }\n",
    "            for swap_log in swap_logs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # mints\n",
    "    mint_logs = uni_v2_contract.events.Mint().get_logs(\n",
    "        fromBlock=block_number, toBlock=block_number + chunk_size - 1\n",
    "    )\n",
    "    mints.extend(\n",
    "        [\n",
    "            {\n",
    "                \"blockNumber\": mint_log[\"blockNumber\"],\n",
    "                \"amount0Minted\": Decimal(mint_log[\"args\"][\"amount0\"]),\n",
    "                \"amount1Minted\": Decimal(mint_log[\"args\"][\"amount1\"]),\n",
    "            }\n",
    "            for mint_log in mint_logs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # burns\n",
    "    burn_logs = uni_v2_contract.events.Burn().get_logs(\n",
    "        fromBlock=block_number, toBlock=block_number + chunk_size - 1\n",
    "    )\n",
    "    burns.extend(\n",
    "        [\n",
    "            {\n",
    "                \"blockNumber\": burn_log[\"blockNumber\"],\n",
    "                \"amount0Burnt\": Decimal(burn_log[\"args\"][\"amount0\"]),\n",
    "                \"amount1Burnt\": Decimal(burn_log[\"args\"][\"amount1\"]),\n",
    "            }\n",
    "            for burn_log in burn_logs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # syncs\n",
    "    sync_logs = uni_v2_contract.events.Sync().get_logs(\n",
    "        fromBlock=block_number, toBlock=block_number + chunk_size - 1\n",
    "    )\n",
    "    syncs.extend(\n",
    "        [\n",
    "            {\n",
    "                \"blockNumber\": sync_log[\"blockNumber\"],\n",
    "                \"reserve0\": Decimal(sync_log[\"args\"][\"reserve0\"]),\n",
    "                \"reserve1\": Decimal(sync_log[\"args\"][\"reserve1\"]),\n",
    "            }\n",
    "            for sync_log in sync_logs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# record the initial reserves\n",
    "initial_reserves = uni_v2_contract.events.Sync().get_logs(\n",
    "    fromBlock=from_block_number - chunk_size + 1, toBlock=from_block_number\n",
    ")[-1][\"args\"]\n",
    "syncs.insert(\n",
    "    0,\n",
    "    {\n",
    "        \"blockNumber\": from_block_number,\n",
    "        \"reserve0\": Decimal(initial_reserves[\"reserve0\"]),\n",
    "        \"reserve1\": Decimal(initial_reserves[\"reserve1\"]),\n",
    "    },\n",
    ")\n",
    "\n",
    "############################################################\n",
    "\n",
    "# convert to DataFrame\n",
    "swaps_df = pl.DataFrame(swaps)\n",
    "mints_df = pl.DataFrame(mints)\n",
    "burns_df = pl.DataFrame(burns)\n",
    "syncs_df = pl.DataFrame(syncs)\n",
    "\n",
    "# save as csv files\n",
    "swaps_df.write_csv(f\"data/onchain_events/{DEX}_{PAIR}_swaps.csv\")\n",
    "mints_df.write_csv(f\"data/onchain_events/{DEX}_{PAIR}_mints.csv\")\n",
    "burns_df.write_csv(f\"data/onchain_events/{DEX}_{PAIR}_burns.csv\")\n",
    "syncs_df.write_csv(f\"data/onchain_events/{DEX}_{PAIR}_syncs.csv\")\n",
    "\n",
    "print(f\"Query for events on {DEX} {PAIR} is done!\")\n",
    "\n",
    "############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
